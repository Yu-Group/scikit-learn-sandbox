{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the output of weighted random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "# Import our custom utilities\n",
    "from imp import reload\n",
    "from sklearn.tree import irf_utils\n",
    "#from utils import irf_utils\n",
    "#reload(irf_jupyter_utils)\n",
    "reload(irf_utils)\n",
    "\n",
    "# Import RF related functions\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When feature_weight = None, the output should match Random Forest.\n",
    "\n",
    "original RF result is stored in feature_weight1 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_weight0 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.tree.irf_utils' has no attribute 'generate_rf_example'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3ae1da160d0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m X_train, X_test, y_train, y_test, rf = irf_utils.generate_rf_example(n_estimators=1000, \n\u001b[0m\u001b[1;32m      2\u001b[0m                                                                              feature_weight=feature_weight0)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn.tree.irf_utils' has no attribute 'generate_rf_example'"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, rf = irf_utils.generate_rf_example(n_estimators=1000, \n",
    "                                                                             feature_weight=feature_weight0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-551524060941>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_rf_tree_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mirf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_rf_tree_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#all_rf_tree_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "all_rf_tree_data = irf_utils.get_rf_tree_data(rf=rf, X_train=X_train, X_test=X_test, y_test=y_test)\n",
    "#all_rf_tree_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04633261  0.01279795  0.04649524  0.05372707  0.00613899  0.01410021\n",
      "  0.04617194  0.08346155  0.00365378  0.00379191  0.01370514  0.00441408\n",
      "  0.01102853  0.03730455  0.00456819  0.00397247  0.00564707  0.00500305\n",
      "  0.00441179  0.00429459  0.11649582  0.01827778  0.14157085  0.11806595\n",
      "  0.01195991  0.01511598  0.03314478  0.11802327  0.00953361  0.00679134]\n"
     ]
    }
   ],
   "source": [
    "# Print the feature importance\n",
    "feature_importances_rank_idx0 = all_rf_tree_data['feature_importances_rank_idx']\n",
    "feature_importances0 = all_rf_tree_data['feature_importances']\n",
    "\n",
    "print(feature_importances0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_feature_importance =[ 0.04153319,  0.0136872,   0.05287382,  0.05537257,  0.00571718,  0.01101297,\n",
    "  0.04525511,  0.08925701,  0.00407582,  0.00337926,  0.01301454,  0.00396505,\n",
    "  0.01022279,  0.03255195,  0.00498767,  0.00438016,  0.00771317,  0.00459407,\n",
    "  0.0037973,   0.00448982,  0.10938616,  0.01690837,  0.14415417,  0.1204331,\n",
    "  0.01276175,  0.01472586,  0.03019196,  0.12449026,  0.00858072,  0.00648698]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When feature_weight is uniform, it should give the same feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_weight1 = [1]*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, rf = irf_jupyter_utils.generate_rf_example(n_estimators=1000, \n",
    "                                                                             feature_weight=feature_weight1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_rf_tree_data = irf_utils.get_rf_tree_data(rf=rf, X_train=X_train, X_test=X_test, y_test=y_test)\n",
    "#all_rf_tree_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04156421  0.01371803  0.05286511  0.0553587   0.00568501  0.01101232\n",
      "  0.04530112  0.08926779  0.0040873   0.00338411  0.01303412  0.00399057\n",
      "  0.01019653  0.03253443  0.00497113  0.00433343  0.00780205  0.00452657\n",
      "  0.00379767  0.00448269  0.10939605  0.01686833  0.14411923  0.12039774\n",
      "  0.01277833  0.01474184  0.03015998  0.12455529  0.00859024  0.00648009]\n"
     ]
    }
   ],
   "source": [
    "#feature importance \n",
    "feature_importances_rank_idx1 = all_rf_tree_data['feature_importances_rank_idx']\n",
    "feature_importances1 = all_rf_tree_data['feature_importances']\n",
    "\n",
    "print(feature_importances1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When feature_weight is weighted, it should give the roughly same feature ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_weight2 = correct_feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, rf = irf_jupyter_utils.generate_rf_example(n_estimators=1000, \n",
    "                                                                             feature_weight=feature_weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_rf_tree_data = irf_utils.get_rf_tree_data(rf=rf, X_train=X_train, X_test=X_test, y_test=y_test)\n",
    "#all_rf_tree_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. feature 22 (0.144119233) and feature 22 (0.362963504)\n",
      " 2. feature 27 (0.124555293) and feature 27 (0.188353629)\n",
      " 3. feature 23 (0.120397738) and feature 23 (0.150679142)\n",
      " 4. feature 20 (0.109396048) and feature  7 (0.099982502)\n",
      " 5. feature  7 (0.089267789) and feature 20 (0.093378339)\n",
      " 6. feature  3 (0.055358700) and feature 26 (0.012814561)\n",
      " 7. feature  2 (0.052865109) and feature  6 (0.012635612)\n",
      " 8. feature  6 (0.045301121) and feature  3 (0.012576257)\n",
      " 9. feature  0 (0.041564208) and feature  2 (0.010215511)\n",
      "10. feature 13 (0.032534434) and feature 21 (0.009935611)\n",
      "11. feature 26 (0.030159979) and feature 13 (0.009467799)\n",
      "12. feature 21 (0.016868331) and feature  1 (0.006934552)\n",
      "13. feature 25 (0.014741839) and feature  0 (0.006521312)\n",
      "14. feature  1 (0.013718027) and feature 24 (0.003568667)\n",
      "15. feature 10 (0.013034123) and feature 25 (0.003392227)\n",
      "16. feature 24 (0.012778328) and feature 10 (0.002856610)\n",
      "17. feature  5 (0.011012323) and feature 28 (0.001972390)\n",
      "18. feature 12 (0.010196528) and feature 12 (0.001924793)\n",
      "19. feature 28 (0.008590244) and feature 29 (0.001764246)\n",
      "20. feature 16 (0.007802045) and feature  5 (0.001437076)\n",
      "21. feature 29 (0.006480088) and feature 16 (0.001074582)\n",
      "22. feature  4 (0.005685009) and feature  4 (0.000997067)\n",
      "23. feature 14 (0.004971128) and feature 11 (0.000704047)\n",
      "24. feature 17 (0.004526568) and feature 18 (0.000688298)\n",
      "25. feature 19 (0.004482690) and feature 14 (0.000629995)\n",
      "26. feature 15 (0.004333429) and feature  8 (0.000596955)\n",
      "27. feature  8 (0.004087299) and feature 17 (0.000582948)\n",
      "28. feature 11 (0.003990568) and feature 19 (0.000560846)\n",
      "29. feature 18 (0.003797667) and feature 15 (0.000504888)\n",
      "30. feature  9 (0.003384114) and feature  9 (0.000286034)\n"
     ]
    }
   ],
   "source": [
    "#feature importance \n",
    "feature_importances_rank_idx2 = all_rf_tree_data['feature_importances_rank_idx']\n",
    "feature_importances2 = all_rf_tree_data['feature_importances']\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d. feature %2d (%10.9f) and feature %2d (%10.9f)\" % (f + 1\n",
    "                                   , feature_importances_rank_idx1[f]\n",
    "                                   , feature_importances1[feature_importances_rank_idx1[f]]\n",
    "                                   , feature_importances_rank_idx2[f]\n",
    "                                   , feature_importances2[feature_importances_rank_idx2[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_iRF_weight1():\n",
    "    #Check when label is random, whether the feature importance of every feature is the same.\n",
    "    n_samples = 1000\n",
    "    n_features = 10\n",
    "    random_state_classifier = 2018\n",
    "    np.random.seed(random_state_classifier)\n",
    "    X_train = np.random.uniform(low=0, high=1, size=(n_samples, n_features))\n",
    "    y_train = np.random.choice([0, 1], size=(n_samples,), p=[.5, .5])\n",
    "    X_test = np.random.uniform(low=0, high=1, size=(n_samples, n_features))\n",
    "    y_test = np.random.choice([0, 1], size=(n_samples,), p=[.5, .5])\n",
    "    all_rf_weights, all_K_iter_rf_data, \\\n",
    "    all_rf_bootstrap_output, all_rit_bootstrap_output, \\\n",
    "    stability_score = irf_utils.run_iRF(X_train=X_train,\n",
    "                                        X_test=X_test,\n",
    "                                        y_train=y_train,\n",
    "                                        y_test=y_test,\n",
    "                                        K=5,\n",
    "                                        n_estimators=20,\n",
    "                                        B=30,\n",
    "                                        random_state_classifier=2018,\n",
    "                                        propn_n_samples=.2,\n",
    "                                        bin_class_type=1,\n",
    "                                        M=20,\n",
    "                                        max_depth=5,\n",
    "                                        noisy_split=False,\n",
    "                                        num_splits=2,\n",
    "                                        n_estimators_bootstrap=5)\n",
    "    assert np.max(all_rf_weights['rf_weight5'])<.135\n",
    "test_iRF_weight1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.09736454  0.90263546]\n",
      "[ 0.09605762  0.90394238]\n",
      "[ 0.09358467  0.90641533]\n",
      "[ 0.09199329  0.90800671]\n",
      "[ 0.08747833  0.91252167]\n",
      "[ 0.08008298  0.91991702]\n",
      "[ 0.07138357  0.92861643]\n",
      "[ 0.06394462  0.93605538]\n",
      "[ 0.05489527  0.94510473]\n",
      "[ 0.05023006  0.94976994]\n",
      "[ 0.0481042  0.9518958]\n",
      "[ 0.04807138  0.95192862]\n",
      "[ 0.04807138  0.95192862]\n",
      "[ 0.04807138  0.95192862]\n",
      "[ 0.04807138  0.95192862]\n",
      "[ 0.04807138  0.95192862]\n",
      "[ 0.04807138  0.95192862]\n",
      "[ 0.04807138  0.95192862]\n",
      "[ 0.04807138  0.95192862]\n",
      "[ 0.04807138  0.95192862]\n"
     ]
    }
   ],
   "source": [
    "def test_iRF_weight2():\n",
    "    #Check when feature 1 fully predict the label, its importance should be 1.\n",
    "    n_samples = 400\n",
    "    n_features = 2\n",
    "    random_state_classifier = 218\n",
    "    np.random.seed(random_state_classifier)\n",
    "    X_train = np.random.uniform(low=0, high=1, size=(n_samples, n_features))\n",
    "    y_train = np.random.choice([0, 1], size=(n_samples,), p=[.5, .5])\n",
    "    X_test = np.random.uniform(low=0, high=1, size=(n_samples, n_features))\n",
    "    y_test = np.random.choice([0, 1], size=(n_samples,), p=[.5, .5])\n",
    "    # first feature is very important\n",
    "    X_train[:,1] = X_train[:,1] + y_train*0.1\n",
    "    X_test[:,1] = X_test[:,1] + y_test*0.1\n",
    "    feature_weight = [.1, .9]\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=20, random_state=random_state_classifier)\n",
    "    for i in range(20):\n",
    "        rf.fit(X=X_train, y=y_train, feature_weight=feature_weight)\n",
    "        all_rf_tree_data = irf_utils.get_rf_tree_data(rf=rf, X_train=X_train, X_test=X_test, y_test=y_test)\n",
    "        print(all_rf_tree_data['feature_importances'])\n",
    "        feature_weight = all_rf_tree_data['feature_importances']\n",
    "    #assert all_rf_weights['rf_weight5'][1] == 1\n",
    "test_iRF_weight2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12001595  0.87998405]\n",
      "[ 0.14080193  0.85919807]\n",
      "[ 0.16464355  0.83535645]\n",
      "[ 0.19866927  0.80133073]\n",
      "[ 0.22244617  0.77755383]\n",
      "[ 0.24774837  0.75225163]\n",
      "[ 0.27378608  0.72621392]\n",
      "[ 0.29184921  0.70815079]\n",
      "[ 0.30800665  0.69199335]\n",
      "[ 0.32903853  0.67096147]\n",
      "[ 0.35541781  0.64458219]\n",
      "[ 0.37805359  0.62194641]\n",
      "[ 0.3931307  0.6068693]\n",
      "[ 0.40570802  0.59429198]\n",
      "[ 0.41020103  0.58979897]\n",
      "[ 0.41011524  0.58988476]\n",
      "[ 0.41011524  0.58988476]\n",
      "[ 0.41011524  0.58988476]\n",
      "[ 0.41011524  0.58988476]\n",
      "[ 0.41011524  0.58988476]\n"
     ]
    }
   ],
   "source": [
    "def test_iRF_weight1():\n",
    "    n_samples = 200\n",
    "    n_features = 2\n",
    "    random_state_classifier = 2018\n",
    "    np.random.seed(random_state_classifier)\n",
    "    X_train = np.random.uniform(low=0, high=1, size=(n_samples, n_features))\n",
    "    y_train = np.random.choice([0, 1], size=(n_samples,), p=[.5, .5])\n",
    "    X_test = np.random.uniform(low=0, high=1, size=(n_samples, n_features))\n",
    "    y_test = np.random.choice([0, 1], size=(n_samples,), p=[.5, .5])\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=50, random_state=random_state_classifier)\n",
    "    # fit the classifier\n",
    "    feature_weight = [.1, .9]\n",
    "    for i in range(20):\n",
    "        rf.fit(X=X_train, y=y_train, feature_weight=feature_weight)\n",
    "        all_rf_tree_data = irf_utils.get_rf_tree_data(rf=rf, X_train=X_train, X_test=X_test, y_test=y_test)\n",
    "        print(all_rf_tree_data['feature_importances'])\n",
    "        feature_weight = all_rf_tree_data['feature_importances']\n",
    "test_iRF_weight1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
